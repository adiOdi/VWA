\chapter{Examples}
Q-table %(flappy bird)

decision tree %(https://www.w3schools.com/python/python_ml_decision_tree.asp)

neural net back propagation 

evolution

\section{Definition}

A decision tree is a form of AI, which is, in comparison, rather easy, and not that complex. It exports a tree consisting of nodes, in which each node answers a yes/no question. 

To create such a tree, data is needed, which is used to shape the tree accordingly.
The hard part is figuring out what question the next node will use for its split. 

One method of measuring the usefulness of a question is the GINI method.
It is calculated as follows: %Gini impurity = 1-(yes/n)^2-(no/n)^2
The smaller this impurity, the less mixed the output is. Which is what we want, as less mixed means the tree is surer of its output. 
So to choose the next node to add to a tree, we measure the GINI impurity of all possible parameters, and choose the one with the smallest impurity. We repeat this process until we only have few samples left in each leaf.

Once created, to find an answer, one must walk down the tree, following the path the nodes lead you, until an end (a leaf) is met.

\section{Usage}
There are two advantages of decision trees in comparison to other forms of AI. One is the ease of understanding it, as we can retrace decisions with relative ease, which is very important in applications where trust in an algorithm is an issue. So for example in an environment where job applications or prison sentences are guided by algorithms, it might be required to be able to check the algorithm for, for example, discriminatory behavior.

Another benefit decision trees offer is the low computational complexity, in both training and application. Of course, they can grow arbitrarily large, but with the right techniques % pruning
they can be brought back to reasonable sizes, which just capture the essentials.

Of course, they are not perfect: For one they require a lot of data to be conclusive, and as they are one of the simpler forms of AI, they need to get quite big to capture complex concepts.