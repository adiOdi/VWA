\chapter{Categorization}
\label{sec:categorization}
% Simple map
As there are many models of artificial intelligence, all working differently, there are also a few distinctions that can be made between them. This thesis will focus on three fairly important distinctions that can be drawn between different models.
\section{Symbolic vs subsymbolic} \label{sec:categorization:symbolicvssub} \cite{SymbolicVsSubsymbolic}
A first big distinction is to make between symbolic and subsymbolic artificial intelligence. 
The difference is in how knowledge about the environment is stored and used.
In symbolic artificial intelligence, knowledge is coded into an agent, while in subsymbolic artificial intelligence knowledge is generally learned by an agent through observations (=data). These observations can either be pre-recorded or acquired by trial and error. So the content of the agents changes, while the structure still remains hard coded.

Which sort of artificial intelligence is better to use really depends on the circumstances: 
Symbolic artificial intelligence for a complex subject normally requires more time to program in comparison, and needs a programmer well versed in the subject. 
Subsymbolic artificial intelligence on the other hand depends on Data being available. Of course, it still is complex to program such a system, but the programmer does not have to know the subject at hand. %cite the thing with programmers not knowing the language but still being able to make a translator for it
Another aspect to keep in mind is the accuracy: Symbolic artificial intelligence can have a 100 percent accuracy rate when programmed correctly, as it is just logical statements and numbers chained together by some operators, while with a subsymbolic artificial intelligence it is normally hard to get a 100 percent accurate model, and most models are capped at some (high) percentage of accuracy. This is in part because of incorrect/incomplete data, but also because of considerations like time and resource constrains while training. Subsymbolic artificial intelligence can still be more accurate in certain domains: When there is no one correct answer but good data for example.
As it is often the case, there is a cost-accuracy payoff, and whether subsymbolic or symbolic artificial intelligence is better suited really depends on the use case. Often they are combined to achieve better results. This work will focus on subsymbolic artificial intelligence. 

A decision tree for example can be made symbolically, but to create one subsymbolically, data is needed, which is used to shape the tree accordingly.
The hard part is figuring out what question the next node will split the data by. 

This requirement for data in subsymbolic artificial intelligence is also the reason why data collection is getting increasingly important in our time. 

\section{Supervised vs unsupervised learning} \cite[p695]{MA}
In supervised learning, labeled data is used. In contrast to this, in unsupervised learning,  unlabeled data is used instead. 
Labeled data is easier to use, but harder to get. Labeled data can be a lot of things, and it does not necessarily have to be human-labeled. A label can also be the output of an action, like, for example, the view time of a video on YouTube presented in different ways, or when the data is the weather yesterday, the label could be the weather today.

In supervised learning, algorithms like backpropagation can be used to model a function, where some input-output pairs are given.

In unsupervised learning the artificial intelligence has to find connections and the structure of the data on its own, as no clear input-output pairs are given.
Here algorithms like support vector machines can be used to cluster data. Unsupervised learning can be used for, for example, serving ads based on interaction with an agent like Facebook. User data can be clustered and analyzed without the need for labeling.

Of course these approaches can also be combined: In so called semi-supervised learning only parts of the data are labeled. This approach brings with it the convenience of not having to label all the data, while still having the greater accuracy and ease of supervised learning. \cite{semisupervised}

\section{Parameterless vs Parameters} \cite[p737]{MA}
In many algorithms, like, for example, neural nets one hurdle is finding a number of parameters big enough to accurately describe a concept, while still not  overfitting [\autoref{sec:overfitting}]. The problem here is that this number of parameters is not universal, and has to be newly reconsidered for each problem. To eliminate this need for a decision, there are also parameterless options. 

So called parameterless approaches do not base their complexity on the problem, but rather on the training data available. Rather than representing the problem with parameters, often a part of the training data/the whole of it is used to come to a decision. This can be, for example, clustering.
One example for a parameterless approach is K-nearest neighbors/Support vector machines \autoref{sec:SVM}

\chapter{Conclusion}
Schreib ich noch neu!
As AI is such a big field, it would be helpful having a classification of the different algorithms, but this is hardly possible, as the edges are very blurred, and different algorithms can be classified very differently depending on specific circumstances.

An approximate classification can be given here:
% this usecase
Decision trees can be categorized as subsymbolical (more symbolical than other algorithms through), are trained supervised, and are a sort of parameterless algorithm.

Neural nets can be categorized as subsymbolical, are trained supervised, and are a sort of parametered algorithm.

Q-Tables can be categorized as subsymbolical, are trained supervised, and are a sort of parameterless algorithm.

SVMs can be categorized as subsymbolical, can be trained unsupervised, and are a parameterless algorithm.

% \begin{tabular}{l p{0.33\textwidth} p{0.33\textwidth}}
%     Metric      & Symbolic  & Subsymbolic\\
%     Complexity  & ? & ? \\
%     Training    & none & yes \\
%     Application & deterministic&could be nondeterministic\\
%     Performance & ? & ? \\
%     Memory      & ? & ? \\
% \end{tabular}

% Complexity: SVM/DT/NN

% accuracy: depends

% training: SVM pro (actually KNN)

% application: depends, DT easier to read

% Performance: Similar, QT fastest, KNN prob? Slow

% resources: =performance, KNN+QT memory
